#hope this helps for windows:
#conda create -n localgpt_llama2_gpu python=3.10.0

#conda activate localgpt_llama2_gpu

##comment out auto-gptq and auto-awq in requirements.txt

#pip install -r requirements.txt

#set CMAKE_ARGS=-DLLAMA_CUBLAS=on FORCE_CMAKE=1
#pip install llama-cpp-python==0.1.83 --no-cache-dir

#python -c "import torch; print(torch.cuda.is_available())"

#(if it gives false it means cuda is not integrated with torch, to make it true do following)

#conda install pytorch=2.0.1 torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia

#pip install autoawq==0.1.5

#pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/

# Natural Language Processing
langchain==0.0.267
chromadb==0.4.6
pdfminer.six==20221105
InstructorEmbedding
sentence-transformers==2.2.2
faiss-cpu
huggingface_hub
transformers
# autoawq; sys_platform != 'darwin'
protobuf==3.20.2; sys_platform != 'darwin'
protobuf==3.20.2; sys_platform == 'darwin' and platform_machine != 'arm64'
protobuf==3.20.3; sys_platform == 'darwin' and platform_machine == 'arm64'
# auto-gptq==0.6.0; sys_platform != 'darwin'
docx2txt
unstructured
unstructured[pdf]

# Utilities
urllib3==1.26.6
accelerate
bitsandbytes ; sys_platform != 'win32'
bitsandbytes-windows ; sys_platform == 'win32'
click
flask
requests
numpy
# Streamlit related
streamlit
streamlit-extras

# Excel File Manipulation
openpyxl

# Machine Learning Frameworks
nltk
scikit-learn
sacrebleu
