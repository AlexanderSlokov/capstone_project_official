#hope this helps for windows:
#conda create -n localgpt_llama2_gpu python=3.10.0

#conda activate localgpt_llama2_gpu

##comment out auto-gptq and auto-awq in requirements.txt

#pip install -r requirements.txt

#set CMAKE_ARGS=-DLLAMA_CUBLAS=on FORCE_CMAKE=1
#pip install llama-cpp-python==0.1.83 --no-cache-dir

#python -c "import torch; print(torch.cuda.is_available())"

#(if it gives false it means cuda is not integrated with torch, to make it true do following)

#conda install pytorch=2.0.1 torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia

#pip install autoawq==0.1.5

#pip install "git+https://github.com/PanQiWei/AutoGPTQ.git@v0.7.1"

#pip install "git+https://github.com/PanQiWei/AutoGPTQ.git@v0.4.2"

# Natural Language Processing
langchain==0.0.267
chromadb==0.4.6
pdfminer.six==20221105
InstructorEmbedding==1.0.1
sentence-transformers==2.2.2
faiss-cpu==1.8.0.post1
huggingface_hub==0.25.1
transformers==4.45.1
unstructured==0.11.2
pikepdf==9.3.0
pypdf==5.0.1
unstructured-inference==0.7.15
unstructured.pytesseract==0.3.13
# Utilities
urllib3==1.26.6
accelerate==0.34.2
bitsandbytes ; sys_platform != 'win32'
bitsandbytes-windows==0.37.5 ; sys_platform == 'win32'
click==8.1.7
flask==3.0.3
requests==2.32.3
numpy==1.26.4

# Streamlit related
streamlit==1.38.0
streamlit-extras==0.0.9

# Excel File Manipulation
openpyxl==3.1.5
